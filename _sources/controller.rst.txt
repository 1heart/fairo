
In the "abstract" droidlet agent, the controller chooses whether to put Tasks on the Task Stack based on the memory state.   In the locobot agent and the craftassist agent subclasses, it consists of


* a `DSL </../../blob/master/base_agent/documents/Action_Dictionary_Spec.md>`_
* a neural semantic parser, which translates natural language into partially specified programs over the DSL
* a Dialogue Manager, Dialogue Stack, and Dialogue objects. 
* the Intepreter, a special Dialogue Object that takes partially specified programs from the DSL and fully specifies them using the Memory
* a set of "default behaviors", run randomly when the Task Stack and Dialogue Stack are empty

Dialogue Objects behave similarly to `Task Objects </../../blob/master/docs/source/tasks.md>`_\ , except they only affect the agent's environment directly by causing the agent to issue utterances (or indirectly by pushing `Task Objects </../../blob/master/docs/source/tasks.md>`_ onto the Task Stack).  In particular, each Dialogue Object has a .step() that is run when it is the highest priority object on the Stack. Dialogue Objects, like `Task Objects </../../blob/master/docs/source/tasks.md>`_ are modular:  a learned model or a heuristic can mediate the Dialogue Object, and the same model or heuristic script can be used across many different agents.    

The Dialogue Manager puts Dialogue Objects on the Dialogue Stack, either on its own, or at the request of a Dialogue Object.  In the locobot and craftassist agent, the manager is powered by a `neural semantic parser </../../blob/master/base_agent/ttad/>`_. 

A sketch of the controller's operation is then

.. code-block::

   if new utterance from human:
        logical_form = semantic_parser.translate(new command)
        if the logical_form denotes a command: 
            push Interpreter(logical_form, agent_memory) onto the DialogueStack
        else if the logical_form denotes some other kind of dialogue the agent can handle:
            push some other appropriate DialogueObject on the DialogueStack
   if the Dialogue Stack is not empty:
        step the highest priority DialogueObject
   if TaskStack is empty:
        maybe place default behaviors on the stack

Interpreter
===========

The `Interpreter </../../blob/master/base_agent/dialogue_objects/intepreter.py>`_ is responsible for using the world state (via `memory </../../blob/master/docs/source/memory.md>`_\ ) and a natural language utterance that has been parsed into a logical form over the agent's DSL from the semantic parser to choose a `Task </../../blob/master/docs/source/tasks.md>`_ to put on the Task Stack.   The `locobot </../../blob/master/locobot/agent/dialogue_objects/loco_intepreter.py>`_ and `craftassist </../../blob/master/craftassist/agent/dialogue_objects/mc_intepreter.py>`_ Interpreters are not the same, but the bulk of the work is done by the shared subinterpreters (in the files *_helper.py) `here </../../blob/master/base_agent/dialogue_objects/>`_.  The subinterpreters, registered in the main Interpreter `here </../../blob/master/base_agent/dialogue_objects/intepreter.py#L55>`_ (and for the specialized versions `here </../../blob/master/locobot/agent/dialogue_objects/loco_intepreter.py#L56>`_ and `here </../../blob/master/craftassist/agent/dialogue_objects/mc_intepreter.py#L61>`_\ ), roughly follow the structure of the DSL.  This arrangement is to allow replacing the (currently heuristic) subinterpreters with learned versions or specializing them to new agents.

Dialogue Stack
==============

Semantic Parser
---------------

Dialogue Objects
================
